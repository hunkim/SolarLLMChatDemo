{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upstage Full Stack LLM with Langchain\n",
    "## Code to Understand!\n",
    "![Overview](./figures/overview.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 install -q openai langchain_community langchain_experimental langchain-upstage sentence-transformers langchainhub langchain-chroma langchain matplotlib python-dotenv tavily-python tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cannot find .env file\n"
     ]
    }
   ],
   "source": [
    "# Set .env and define these:\n",
    "# UPSTAGE_API_KEY from https://console.upstage.ai/\n",
    "# TAVILY_API_KEY https://app.tavily.com\n",
    "# NEWS_API_KEY from https://newsapi.org/\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interacting with the solar-1-mini-chat Model\n",
    "\n",
    "This Python code demonstrates how to use the OpenAI SDK to interact with the solar-1-mini-chat model provided by Upstage AI.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Import necessary libraries: `os`, `openai`, and `pprint`.\n",
    "2. Set up the OpenAI client with the SOLAR API KEY and base URL.\n",
    "3. Create a chat completion request using `client.chat.completions.create()`.\n",
    "   - Specify the model: \"solar-1-mini-chat\".\n",
    "   - Provide a list of messages, including the system message and user message.\n",
    "4. Handle the model's response:\n",
    "   - Print the entire response using `pprint()`.\n",
    "   - Print the content of the assistant's message using `response.choices[0].message.content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='fc3ec9be-3c82-4d72-87a8-7ce59fad7cf7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Ah, Korea! That's a fascinating place with a rich history and culture. I've always wanted to visit. The Korean Demilitarized Zone (DMZ) is on my list of places to see. It's a strip of land dividing North and South Korea, and it's one of the most heavily fortified borders in the world. It's a reminder of the Cold War and the ongoing division of Korea.\\n\\nI'm also interested in learning more about the traditional Korean arts, like calligraphy, pottery, and music. The beauty of their ceramics is something I'd love to study up close. And of course, I can't resist trying out the local cuisine. Kimchi, bulgogi, and bibimbap are all on my must-try list!\", role='assistant', function_call=None, tool_calls=None))], created=1715011246, model='solar-1-mini-chat-240502', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=179, prompt_tokens=26, total_tokens=205))\n",
      "Message only:\n",
      "(\"Ah, Korea! That's a fascinating place with a rich history and culture. I've \"\n",
      " 'always wanted to visit. The Korean Demilitarized Zone (DMZ) is on my list of '\n",
      " \"places to see. It's a strip of land dividing North and South Korea, and it's \"\n",
      " \"one of the most heavily fortified borders in the world. It's a reminder of \"\n",
      " 'the Cold War and the ongoing division of Korea.\\n'\n",
      " '\\n'\n",
      " \"I'm also interested in learning more about the traditional Korean arts, like \"\n",
      " 'calligraphy, pottery, and music. The beauty of their ceramics is something '\n",
      " \"I'd love to study up close. And of course, I can't resist trying out the \"\n",
      " 'local cuisine. Kimchi, bulgogi, and bibimbap are all on my must-try list!')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pprint import pprint\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=os.environ[\"UPSTAGE_API_KEY\"], base_url=\"https://api.upstage.ai/v1/solar\"\n",
    ")\n",
    "gc_result = client.chat.completions.create(\n",
    "    model=\"solar-1-mini-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"What about Korea?\"},\n",
    "    ],\n",
    ")\n",
    "pprint(gc_result)\n",
    "print(\"Message only:\")\n",
    "pprint(gc_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Few-Shot Examples in Chat Completions\n",
    "\n",
    "This Python code demonstrates how to use few-shot examples to provide context and guide the model's responses.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Set up the OpenAI client with the SOLAR API KEY and base URL.\n",
    "2. Create a chat completion request using `client.chat.completions.create()`.\n",
    "   - Specify the model: \"solar-1-mini-chat\".\n",
    "   - Provide a list of messages, including:\n",
    "     - System message: Defines the assistant's role.\n",
    "     - Few-shot examples: Provide context and desired behavior.\n",
    "     - User input: The actual user query.\n",
    "3. Handle the model's response:\n",
    "   - Print the entire response using `pprint()`.\n",
    "   - Print the content of the assistant's message using `response.choices[0].message.content`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='d7998983-8970-4118-be37-3e2ebdbf0b67', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"Oh, I know that too! It's Seoul!!\", role='assistant', function_call=None, tool_calls=None))], created=1715011248, model='solar-1-mini-chat-240502', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=17, prompt_tokens=55, total_tokens=72))\n",
      "Message only:\n",
      "\"Oh, I know that too! It's Seoul!!\"\n"
     ]
    }
   ],
   "source": [
    "# few shots: examples or history\n",
    "gc_result = client.chat.completions.create(\n",
    "    model=\"solar-1-mini-chat\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        # examples\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"I know of it. It's Paris!!\"},\n",
    "        # user input\n",
    "        {\"role\": \"user\", \"content\": \"What about Korea?\"},\n",
    "    ],\n",
    ")\n",
    "pprint(gc_result)\n",
    "print(\"Message only:\")\n",
    "pprint(gc_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building LLM Applications with LangChain\n",
    "\n",
    "This Python code demonstrates how to use the LangChain library to build applications with Large Language Models (LLMs). It covers the basic steps of defining an LLM, creating a chat prompt, defining a chain, and invoking the chain.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Define your favorite LLM:\n",
    "   - Import the `ChatUpstage` class from `langchain_upstage`.\n",
    "   - Create an instance of `ChatUpstage` and assign it to the variable `llm`.\n",
    "\n",
    "2. Define a chat prompt:\n",
    "   - Import the `ChatPromptTemplate` class from `langchain_core.prompts`.\n",
    "   - Create a `ChatPromptTemplate` instance using the `from_messages()` method.\n",
    "   - Provide a list of messages, including system messages, example conversations, and user input.\n",
    "\n",
    "3. Define a chain:\n",
    "   - Import the `StrOutputParser` class from `langchain_core.output_parsers`.\n",
    "   - Create a chain by combining the `rag_with_history_prompt`, `llm`, and `StrOutputParser()` using the pipe (`|`) operator.\n",
    "\n",
    "4. Invoke the chain:\n",
    "   - Call the `invoke()` method on the `chain` object, passing an empty dictionary (`{}`) as the input.\n",
    "   - Print the response obtained from the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Korea, it's Seoul. I know about that too!\n"
     ]
    }
   ],
   "source": [
    "# langchain, 1. llm define, 2. prompt define, 3. chain, 4. chain.invoke\n",
    "\n",
    "# 1. define your favorate llm, solar\n",
    "from langchain_upstage import ChatUpstage\n",
    "llm= ChatUpstage()\n",
    "\n",
    "# 2. define chat prompt\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"What is the capital of France?\"),\n",
    "        (\"ai\", \"I know of it. It's Paris!!\"),\n",
    "        (\"human\", \"What about Korea?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 3. define chain \n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. invoke the chain\n",
    "gc_result = chain.invoke({})\n",
    "print(gc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameterized Prompt Templates in LangChain\n",
    "\n",
    "### Overview\n",
    "\n",
    "- Prompt templates allow for reusable and modular prompts\n",
    "- They improve maintainability compared to using raw prompt strings\n",
    "- {country} value can be set from outside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Korea is Seoul!!\n",
      "---\n",
      "Tokyo is the capital of Japan, indeed.\n"
     ]
    }
   ],
   "source": [
    "# parameterized prompt template\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        (\"human\", \"What is the capital of France?\"),\n",
    "        (\"ai\", \"I know of it. It's Paris!!\"),\n",
    "        (\"human\", \"What about {country}?\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "\n",
    "# 4. invoke chain with param\n",
    "print(chain.invoke({\"country\": \"Korea\"}))\n",
    "print(\"---\")\n",
    "print(chain.invoke({\"country\": \"Japan\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leveraging Message History in LangChain Prompts\n",
    "\n",
    "- LangChain provides powerful tools for managing conversation history\n",
    "- `MessagesPlaceholder` allows for dynamic inclusion of message history\n",
    "- `HumanMessage` and `AIMessage` classes represent individual messages\n",
    "- Combining message history with user input enables context-aware responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, there are two Koreas: North Korea and South Korea. The capital of South Korea is Seoul.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# More general chat\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant.\"),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "history = [\n",
    "    HumanMessage(\"What is the capital of France?\"),\n",
    "    AIMessage(\"It's Paris!!\"),\n",
    "]\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "gc_result = chain.invoke({\"history\": history, \"input\": \"What about Korea?\"})\n",
    "print(gc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leveraging Layout Analyzer and LangChain for Efficient Text Splitting and Vectorization\n",
    "\n",
    "- Upstage Layout Analyzer extracts layouts, tables, and figures from any document\n",
    "- LangChain provides powerful tools for text splitting and vectorization\n",
    "![Layout Analyzer](./figures/la.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_upstage import (\n",
    "    UpstageLayoutAnalysisLoader,\n",
    "    UpstageGroundednessCheck,\n",
    "    ChatUpstage,\n",
    "    UpstageEmbeddings,\n",
    ")\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "layzer = UpstageLayoutAnalysisLoader(\"./solar_paper.pdf\", output_type=\"html\")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "docs_one_page = layzer.load()  # or layzer.lazy_load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"<table id='0' \"\n",
      " \"style='font-size:14px'><tr><td>Model</td><td>Size</td><td>Type</td><td>H6 \"\n",
      " '(Avg.)</td><')\n"
     ]
    }
   ],
   "source": [
    "for doc in docs_one_page:\n",
    "    pprint(doc.page_content[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation (RAG) for Question Answering\n",
    "\n",
    "- RAG combines retrieval and generation to enhance LLM performance on specific tasks\n",
    "- Relevant context is retrieved from external data sources and added to the prompt\n",
    "- The augmented prompt is then passed to the LLM for generating a response\n",
    "- RAG is particularly useful for question answering on custom datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE1\n",
      " Table 6 provides a performance comparison among the merge candidates. It showcases the results of two models, 'Cand. 1' and 'Cand. 2', which were trained using the same setting as 'DPO v2' and 'DPO v3', respectively, but with slightly different hyperparameters to maximize each model's respective strengths.\n",
      "\n",
      "The table reveals that 'Cand. 1' exhibits high GSM8K scores but relatively low scores for the other tasks, whereas 'Cand. 2' demonstrates low scores for GSM8K but high scores for the other tasks. The purpose of merging these two models is to create a model that retains the high scores for non-GSM8K tasks from 'Cand. 1' while also achieving a higher GSM8K score than 'Cand. 2'.\n",
      "\n",
      "The table also presents the results of merging these two models using different methods. The merge methods include:\n",
      "\n",
      "1. Average (a, b), where 'a' and 'b' denote the weighting for 'Cand. 1' and 'Cand. 2' when averaging weights.\n",
      "2. SLERP (Slerp), a spherical interpolation method.\n",
      "\n",
      "The table shows that the different merge methods have little effect on the H6 scores. The scores for the individual tasks also do not differ by much, suggesting that as long as the merge candidates have sufficiently different strengths, the exact merge method may not be as crucial.\n",
      "\n",
      "Based on the results, 'Merge v1', which is the merged model using the average method with weights (0.5, 0.5), was chosen as the final SOLAR 10.7B-Instruct model.\n"
     ]
    }
   ],
   "source": [
    "# More general chat\n",
    "rag_with_history_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question considering the history of the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "---\n",
    "CONTEXT:\n",
    "{context}\n",
    "         \"\"\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "history = [\n",
    "]\n",
    "\n",
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "query1 = \"Performance comparison amongst the merge candidate\"\n",
    "response1 = chain.invoke({\"history\": history, \"context\": docs_one_page[0].page_content, \"input\": query1})\n",
    "print(\"RESPONSE1\\n\", response1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESPONSE2\n",
      " Ablation studies are experiments designed to understand the impact of specific components or aspects of a model by systematically removing or modifying them. In the context of the SOLAR 10.7B and SOLAR 10.7B-Instruct models, there are two main types of ablation studies presented in the context:\n",
      "\n",
      "1. Ablation Studies on the Instruction Tuning Stage:\n",
      "\n",
      "These ablation studies aim to understand the effects of different training datasets on the instruction tuning stage. The models ablated in this study are prefixed with 'SFT' for supervised fine-tuning. The study includes models trained on different combinations of Alpaca-GPT4, OpenOrca, and Synth. Math-Instruct datasets.\n",
      "\n",
      "The results show that adding the Synth. Math-Instruct dataset is beneficial and can improve the performance on the GSM8K task. Additionally, merging models trained with and without OpenOrca can boost performance, as it leads to a model that performs well generally.\n",
      "\n",
      "2. Ablation Studies on the Alignment Tuning Stage:\n",
      "\n",
      "These ablation studies focus on understanding the effects of different alignment datasets used during direct preference optimization (DPO) and different SFT base models used for initialization. The ablated models are named with the 'DPO' prefix to indicate the alignment tuning stage.\n",
      "\n",
      "For the DPO stage, the study investigates the impact of using different alignment datasets, specifically Ultrafeedback Clean and Synth. Math-Alignment. The results show that adding Synth. Math-Alignment is beneficial for the H6 score, but merging models trained with and without Synth. Math-Alignment does not lead to further improvements.\n",
      "\n",
      "For the SFT base models, the study compares using 'SFT v3' and 'SFT v3+v4' as the base models for DPO. The results indicate that the performance gaps in certain tasks in the SFT base models do not always carry over to the alignment-tuned models.\n",
      "\n",
      "Finally, the study also investigates different merge methods for obtaining the final alignment-tuned model. The results suggest that as long as the merge candidates have sufficiently different strengths, the exact merge method may not be as crucial.\n",
      "\n",
      "In summary, the ablation studies provide insights into the impact of different datasets and base models on the instruction and alignment tuning stages of the SOLAR 10.7B and SOLAR 10.7B-Instruct models. These findings help in understanding the contributions of various components to the overall performance of the models.\n"
     ]
    }
   ],
   "source": [
    "history = [\n",
    "    HumanMessage(query1),\n",
    "    AIMessage(response1)\n",
    "]\n",
    "query2 = \"How about Ablation studies?\"\n",
    "response2 = chain.invoke({\"history\": history, \"context\": docs_one_page[0].page_content, \"input\": query2})\n",
    "print(\"RESPONSE2\\n\", response2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load something big\n",
    "layzer = UpstageLayoutAnalysisLoader(\"./kim-tse-2008.pdf\", output_type=\"html\")\n",
    "# For improved memory efficiency, consider using the lazy_load method to load documents page by page.\n",
    "docs = layzer.load()  # or layzer.lazy_load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  RAG Limitations\n",
    "- LLM does not have long enough context length\n",
    "- Sending long, irrelevant info is inefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"This model's maximum context length is 32768 tokens. However, your messages resulted in 35028 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "query1 = \"What is bug classification?\"\n",
    "\n",
    "try:    \n",
    "    response1 = chain.invoke({\"history\": history, \"context\": docs[0].page_content, \"input\": query1})\n",
    "    print(response1)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded input: ['<|startoftext|>', '▁Hi', ',', '▁how', '▁are', '▁you', '?']\n",
      "Number of tokens: 7\n"
     ]
    }
   ],
   "source": [
    "from tokenizers import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer.from_pretrained(\"upstage/solar-1-mini-tokenizer\")\n",
    "text = \"Hi, how are you?\"\n",
    "enc = tokenizer.encode(text)\n",
    "print(\"Encoded input:\", enc.tokens)\n",
    "\n",
    "number_of_tokens = len(enc.tokens)\n",
    "print(\"Number of tokens:\", number_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_of_tokens(text):\n",
    "    return len(tokenizer.encode(text).tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 20524\n"
     ]
    }
   ],
   "source": [
    "# First document has short context (under 32k)\n",
    "text = docs_one_page[0].page_content\n",
    "number_of_tokens = num_of_tokens(text)\n",
    "print(\"Number of tokens:\", number_of_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens: 34553\n"
     ]
    }
   ],
   "source": [
    "# Second document has long context (over 32k)\n",
    "text = docs[0].page_content\n",
    "number_of_tokens = num_of_tokens(text)\n",
    "print(\"Number of tokens:\", number_of_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Efficient Text Splitting and Indexing with LangChain\n",
    "\n",
    "### 1. Load Documents\n",
    "\n",
    "The first step is to load the source documents that will be used to augment the language model's knowledge\n",
    "This could be done by reading files from disk, pulling from a database, scraping web pages, etc.\n",
    "The goal is to get the raw text content into a format that can be further processed\n",
    "\n",
    "### 2. Chunking/Splitting\n",
    "\n",
    "* Long documents need to be broken down into smaller chunks that are a manageable size for embedding and retrieval\n",
    "Common approaches include:\n",
    "  * Fixed-size chunking - split text into equal sized chunks based on character or token count \n",
    "  * Semantic chunking - split based on semantic boundaries like sentences, paragraphs, or sections\n",
    "  * Hierarchical chunking - create chunks at multiple levels of granularity\n",
    "The ideal chunk size depends on the embedding model, retrieval use case, and downstream task\n",
    "\n",
    "### 3. Embedding & Indexing\n",
    "\n",
    "* The text chunks are converted to vector embeddings using a model like Upstage embeddings\n",
    "* The embeddings are indexed and stored in a vector database to enable efficient similarity search \n",
    "* Metadata about the source chunks can also be stored alongside the embeddings\n",
    "\n",
    "### 4. Retrieval\n",
    "\n",
    "* At query time, the user's question is itself embedded as a query vector\n",
    "* The query embedding is used to find the most similar document chunks in the vector index \n",
    "* Top-k most relevant chunks are retrieved and can be used to augment the prompt sent to the language model to generate an answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splits: 82\n"
     ]
    }
   ],
   "source": [
    "# RAG 1. load doc (done), 2. chunking, splits, 3. embeding - indexing, 4. retrieve \n",
    "\n",
    "# 2. Split\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100, length_function=num_of_tokens)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "print(\"Splits:\", len(splits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "split_lengths = [num_of_tokens(split.page_content) for split in splits]\n",
    "\n",
    "# Create a bar graph\n",
    "plt.bar(range(len(splits)), split_lengths)\n",
    "plt.title('RecursiveCharacterTextSplitter')\n",
    "plt.xlabel('Split Index')\n",
    "plt.ylabel('Split Content Length')\n",
    "plt.xticks(range(len(splits)), [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.14 s, sys: 65.2 ms, total: 2.2 s\n",
      "Wall time: 54.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 3. Embed & indexing\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=UpstageEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"of this article, please send e-mail to:<br>tse@computer.org, and reference IEEECS Log Number TSE-0061-0306.<br>Digital Object Identifier no. 10.1109/TSE.2007.70773.</p><br><p id='13' style='font-size:18px'>introduced bugs immediately. Several bug-finding techni-<br>ques could be used, including code inspections, unit testing,<br>and the use of static analysis tools. Since these steps would<br>be taken right after a code change was made, the developer<br>would still retain the full mental context of the change. This<br>holds promise for reducing the time required to find<br>software bugs and reducing the time that bugs stay resident<br>in software before removal.</p><br><p id='14' style='font-size:18px'>This paper presents a new technique, called change<br>classification, for predicting bugs in file-level software<br>changes (a set of line ranges in a single file changed since<br>the previous revision) by using machine learning classifica-<br>tion algorithms. A key insight behind this work is viewing<br>bug prediction in changes as a kind of a classification<br>problem, that is, assigning each change made into one of the<br>two classes: clean changes or buggy changes.</p><br><p id='15' style='font-size:18px'>The change classification technique involves two steps:<br>training and classification. The change classification algo-<br>rithms learn from a training set, that is, a collection of<br>changes that are known to belong to an existing class, that<br>is, the changes are labeled with the known class. Features\" metadata={'split': 'none', 'total_pages': 16, 'type': 'html'}\n"
     ]
    }
   ],
   "source": [
    "# 4. retrive\n",
    "retriever = vectorstore.as_retriever(k=10)\n",
    "result_docs = retriever.invoke(\"What is Bug Classification?\")\n",
    "print(result_docs[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overview](./figures/semantic_chunker.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-2. SemanticChunker Split\n",
    "from langchain_community.utils.math import cosine_similarity\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def semantic_chunker(\n",
    "    docs,\n",
    "    min_chunk_size=100,\n",
    "    chunk_overlap=10,\n",
    "    max_chunk_size=1000,\n",
    "    merge_threshold=0.7,\n",
    "    embeddings=UpstageEmbeddings(),\n",
    "):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=min_chunk_size, chunk_overlap=chunk_overlap, length_function=num_of_tokens\n",
    "    )\n",
    "    init_splits = text_splitter.split_documents(docs)\n",
    "    splits = []\n",
    "\n",
    "    base_split_text = None\n",
    "    base_split_emb = None\n",
    "    for split in init_splits:\n",
    "        if base_split_text is None:\n",
    "            base_split_text = split.page_content\n",
    "            base_split_emb = embeddings.embed_query(base_split_text)\n",
    "            continue\n",
    "\n",
    "        split_emb = embeddings.embed_query(split.page_content)\n",
    "        distance = cosine_similarity(X=[base_split_emb], Y=[split_emb])\n",
    "        if (\n",
    "            distance[0][0] < merge_threshold\n",
    "            or num_of_tokens(base_split_text) + num_of_tokens(split.page_content) > max_chunk_size\n",
    "        ):\n",
    "            splits.append(Document(page_content=base_split_text))\n",
    "            base_split_text = split.page_content\n",
    "            base_split_emb = split_emb\n",
    "        else:\n",
    "            base_split_text += split.page_content\n",
    "\n",
    "    if base_split_text:\n",
    "        splits.append(Document(page_content=base_split_text))\n",
    "\n",
    "    return splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HuggingFaceEmbeddings\n",
    "Since it's just an approximation, it's acceptable to use very light embedding models like KLUE, https://huggingface.co/klue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name /Users/junhyunpark/.cache/torch/sentence_transformers/klue_roberta-small. Creating a new one with MEAN pooling.\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at /Users/junhyunpark/.cache/torch/sentence_transformers/klue_roberta-small and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.1 s, sys: 2.38 s, total: 3.48 s\n",
      "Wall time: 3.49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "hfembeddings = HuggingFaceEmbeddings(model_name=\"klue/roberta-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SemanticChunker Splits: 100\n",
      "CPU times: user 38.3 s, sys: 10.4 s, total: 48.8 s\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "splits = semantic_chunker(docs,  merge_threshold=0.8, embeddings=hfembeddings)\n",
    "print(\"SemanticChunker Splits:\", len(splits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "split_lengths = [num_of_tokens(split.page_content) for split in splits]\n",
    "\n",
    "# Create a bar graph\n",
    "plt.bar(range(len(splits)), split_lengths)\n",
    "plt.xlabel('Split Index')\n",
    "plt.ylabel('Split Content Length')\n",
    "plt.title('Semantic Chunker Split Page Content Lengths')\n",
    "plt.xticks(range(len(splits)), [])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChromaParallel Class: Parallel Document Embedding\n",
    "The ChromaParallel class is an extension of the Chroma class to enable parallel processing of document embedding and storage using multiple worker processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "class ChromaParallel(Chroma):\n",
    "\n",
    "    async def afrom_documents(documents, embedding, num_workers=2):\n",
    "        db = Chroma(embedding_function=embedding)\n",
    "        # create list of num_workers empty lists\n",
    "        doc_groups = [[] for _ in range(num_workers)]     \n",
    "\n",
    "        for i in range(len(documents)):\n",
    "            doc_groups[i % num_workers].append(documents[i])\n",
    "       \n",
    "        tasks = [db.aadd_documents(group) for group in doc_groups]\n",
    "        await asyncio.gather(*tasks)\n",
    "        return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='CLASSIFYING SOFTWARE CHANGES: CLEAN OR BUGGY?</header><br><header id=\\'146\\' style=\\'font-size:14px\\'>189</header><figure><img id=\\'147\\' style=\\'font-size:14px\\' alt=\"1'\n",
      "Wall time: 12.66 sec\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "now = time.time()\n",
    "# 3. Embed & indexing\n",
    "loop = asyncio.get_event_loop()\n",
    "vectorstore = await ChromaParallel.afrom_documents(documents=splits, embedding=UpstageEmbeddings(), num_workers=10)\n",
    "retriever = vectorstore.as_retriever(k=10)\n",
    "\n",
    "# 4. retrive\n",
    "result_docs = retriever.invoke(\"What is Bug Classification?\")\n",
    "print(result_docs[1])\n",
    "print(f\"Wall time: {time.time() - now:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug classification is a process that involves categorizing software bugs based on their characteristics, such as their severity, the component of the software they affect, or the type of error they represent. This process helps developers and quality assurance teams to prioritize and manage bugs more effectively.\n",
      "\n",
      "The bug classification process typically works as follows:\n",
      "\n",
      "1. **Identification**: The first step in bug classification is to identify the bugs in the software. This can be done through various methods, such as testing, code reviews, or user feedback.\n",
      "\n",
      "2. **Categorization**: Once the bugs have been identified, they are categorized based on certain criteria. This can include:\n",
      "   - **Severity**: Bugs are classified based on how much they impact the software's functionality and the user's experience. Severity levels can range from minor issues that don't significantly affect the software to critical bugs that cause the software to crash or behave unexpectedly.\n",
      "   - **Component**: Bugs are often categorized based on the component of the software they affect. For example, a bug might be classified as a UI bug, a database bug, or a server-side bug.\n",
      "   - **Type**: Bugs can also be classified based on their type, such as logic errors, memory leaks, or security vulnerabilities.\n",
      "\n",
      "3. **Prioritization**: After bugs have been classified, they are prioritized based on their severity and other factors, such as their impact on the user experience or the business goals of the software. This helps developers to focus their efforts on the most critical bugs first.\n",
      "\n",
      "4. **Documentation**: The classified bugs are then documented in a bug tracking system, such as Jira or Bugzilla. This documentation includes information about the bug, its classification, and its status, which helps other team members understand the bug and its impact.\n",
      "\n",
      "5. **Resolution**: Developers work to fix the bugs, and once they are resolved, the bugs are marked as closed in the bug tracking system.\n",
      "\n",
      "Bug classification is an important part of software development and quality assurance. It helps teams to manage and prioritize bugs effectively, which can lead to better software quality and a better user experience.\n"
     ]
    }
   ],
   "source": [
    "# Finally query using RAG\n",
    "query = \"What is bug classification? How it works?\"\n",
    "result_docs = retriever.invoke(query)\n",
    "\n",
    "gc_result = chain.invoke({\"history\": history, \"context\": result_docs, \"input\": query})\n",
    "print(gc_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bug classification is beneficial for several reasons:\n",
      "\n",
      "1. **Prioritization**: By categorizing bugs based on their severity and other factors, teams can prioritize their efforts on the most critical issues first. This helps to ensure that the most significant problems are addressed promptly, improving the overall quality of the software.\n",
      "\n",
      "2. **Efficiency**: Classifying bugs can help developers and QA teams work more efficiently. By having a clear understanding of the type and severity of each bug, they can allocate their time and resources more effectively, reducing the time it takes to resolve issues.\n",
      "\n",
      "3. **Transparency**: A well-organized bug tracking system provides transparency into the software development process. Stakeholders, including project managers, clients, and other team members, can easily see the status of bugs and the progress being made in resolving them.\n",
      "\n",
      "4. **Consistency**: A standardized bug classification system ensures that all team members use the same terminology and criteria when categorizing bugs. This consistency helps to avoid confusion and ensures that everyone is on the same page regarding the state of the software.\n",
      "\n",
      "5. **Improved Communication**: Classifying bugs can improve communication within the team. When bugs are clearly categorized, it's easier for developers to explain the nature and impact of a bug to other team members, which can facilitate better collaboration and problem-solving.\n",
      "\n",
      "6. **Data Analysis**: Over time, the data collected from bug classification can be analyzed to identify trends and patterns. This can help teams to improve their development processes, identify areas where they may need to focus more on testing, and make informed decisions about future development efforts.\n",
      "\n",
      "In summary, bug classification is a valuable tool that helps teams to manage and prioritize bugs more effectively, leading to better software quality and a more efficient development process.\n"
     ]
    }
   ],
   "source": [
    "history = [\n",
    "    HumanMessage(query),\n",
    "    AIMessage(gc_result)\n",
    "]\n",
    "\n",
    "query = \"Why it is good?\"\n",
    "result_docs = retriever.invoke(query)\n",
    "\n",
    "gc_result = chain.invoke({\"history\": history, \"context\": result_docs, \"input\": query})\n",
    "print(gc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the Code: Query Expander\n",
    "\n",
    "The provided code demonstrates a query expansion technique used in Retrieval Augmented Generation (RAG) systems. The main goal is to generate multiple variations of a given user query to retrieve relevant documents from a vector database more effectively. By generating different perspectives on the user query, the system aims to overcome some limitations of distance-based similarity search.\n",
    "\n",
    "The code defines a function called `query_expander` that takes a user query as input and returns a list of expanded queries. It uses three different query expansion templates:\n",
    "\n",
    "1. Multi Query: Generates five different versions of the user query to retrieve relevant documents from different perspectives.\n",
    "2. RAG-Fusion: Generates four related search queries based on the input query.\n",
    "3. Decomposition: Breaks down the input query into three sub-questions that can be answered in isolation.\n",
    "\n",
    "The expanded queries are generated using the LangChain library, specifically the `ChatUpstage` model, and the results are parsed using the `StrOutputParser`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Can you explain the DUS methodology created by Upstage?',\n",
      " '2. What is the DUS approach developed by Upstage and how does it work?',\n",
      " '3. Can you provide an overview of the DUS technique developed by Upstage?',\n",
      " '4. How does the DUS approach developed by Upstage differ from other similar '\n",
      " 'methods?',\n",
      " '5. What are the key features of the DUS methodology developed by Upstage?',\n",
      " '1. \"DUS approach by Upstage: definition and explanation\"',\n",
      " '2. \"How does the DUS approach by Upstage work?\"',\n",
      " '3. \"Applications of the DUS approach developed by Upstage\"',\n",
      " '4. \"Comparing the DUS approach by Upstage with other similar methods\"',\n",
      " '1. What is the DUS approach in the context of Upstage?',\n",
      " '2. How does the DUS approach differ from other methods in its field?',\n",
      " '3. What are the key components and steps involved in the DUS approach '\n",
      " 'developed by Upstage?']\n"
     ]
    }
   ],
   "source": [
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "def query_expander(query):\n",
    "    # Multi Query: Different Perspectives\n",
    "    multi_query_template = \"\"\"You are an AI language model assistant. Your task is to generate five \n",
    "    different versions of the given user question to retrieve relevant documents from a vector \n",
    "    database. By generating multiple perspectives on the user question, your goal is to help\n",
    "    the user overcome some of the limitations of the distance-based similarity search. \n",
    "    Provide these alternative questions separated by newlines. Original question: {query}\"\"\"\n",
    "\n",
    "    # RAG-Fusion: Related\n",
    "    rag_fusion_template = \"\"\"You are a helpful assistant that generates multiple search queries based on a single input query. \\n\n",
    "    Generate multiple search queries related to: {query} \\n\n",
    "    Output (4 queries):\"\"\"\n",
    "\n",
    "    # Decomposition\n",
    "    decomposition_template = \"\"\"You are a helpful assistant that generates multiple sub-questions related to an input question. \\n\n",
    "    The goal is to break down the input into a set of sub-problems / sub-questions that can be answers in isolation. \\n\n",
    "    Generate multiple search queries related to: {query} \\n\n",
    "    Output (3 queries):\"\"\"\n",
    "\n",
    "    query_expander_templates = [\n",
    "        multi_query_template,\n",
    "        rag_fusion_template,\n",
    "        decomposition_template,\n",
    "    ]\n",
    "\n",
    "    expanded_queries = []\n",
    "    for template in query_expander_templates:\n",
    "        prompt_perspectives = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "        generate_queries = (\n",
    "            prompt_perspectives\n",
    "            | ChatUpstage(temperature=0)\n",
    "            | StrOutputParser()\n",
    "            | (lambda x: x.split(\"\\n\"))\n",
    "        )\n",
    "        expanded_queries += generate_queries.invoke({\"query\": query})\n",
    "\n",
    "    return expanded_queries\n",
    "\n",
    "\n",
    "expanded_queries = query_expander(\"What is the DUS approach developed by Upstage?\")\n",
    "pprint(expanded_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for:  1. What is the process of categorizing bugs in software development?\n",
      "Search for:  2. How does bug classification benefit software development?\n",
      "Search for:  3. What are the different types of bugs and how are they classified?\n",
      "Search for:  4. What are the advantages of bug classification in software development?\n",
      "Search for:  5. How does bug classification help in identifying and fixing software issues?\n",
      "Search for:  1. \"Bug classification techniques\"\n",
      "Search for:  2. \"Importance of bug classification in software development\"\n",
      "Search for:  3. \"Bug classification tools and methodologies\"\n",
      "Search for:  4. \"Benefits of effective bug classification for software quality assurance\"\n",
      "Search for:  1. What is the definition of bug classification in software development?\n",
      "Search for:  2. What are the benefits of bug classification for software development teams?\n",
      "Search for:  3. How does bug classification contribute to efficient and effective software development processes?\n",
      "Search for:  What is bug classification? Why it is good?\n",
      "expended_result_docs 13\n",
      "Unique docs: 13\n",
      "Bug classification is the process of categorizing software bugs based on their characteristics, such as their severity, the component of the software they affect, or the type of error they represent. This process helps developers and quality assurance teams to prioritize and manage bugs more effectively.\n",
      "\n",
      "Bug classification is good for several reasons:\n",
      "\n",
      "1. **Prioritization**: By classifying bugs, teams can prioritize them based on their severity and impact on the software's functionality and user experience. This allows developers to focus on the most critical bugs first, ensuring that the software remains stable and functional.\n",
      "\n",
      "2. **Efficient Resource Allocation**: Bug classification helps teams to allocate resources more efficiently. By understanding the nature and extent of the bugs, teams can assign tasks to the right developers, ensuring that the most qualified team members work on the most complex issues.\n",
      "\n",
      "3. **Improved Software Quality**: Effective bug classification leads to better software quality. By identifying and fixing bugs early in the development process, teams can prevent issues from propagating through the software, reducing the likelihood of major problems down the line.\n",
      "\n",
      "4. **Enhanced User Experience**: By prioritizing and fixing bugs that impact the user experience, teams can ensure that their software is intuitive, reliable, and easy to use. This can lead to higher user satisfaction and adoption rates.\n",
      "\n",
      "5. **Better Communication**: Bug classification helps teams to communicate more effectively about the software's issues. By using a common language and taxonomy, team members can discuss bugs more efficiently and make informed decisions about how to address them.\n",
      "\n",
      "In summary, bug classification is a good practice because it helps teams to manage and prioritize bugs effectively, allocate resources efficiently, improve software quality, enhance the user experience, and facilitate better communication within the team.\n"
     ]
    }
   ],
   "source": [
    "# Finally query using RAG\n",
    "oroginal_query = \"What is bug classification? Why it is good?\"\n",
    "expanded_queries = query_expander(oroginal_query)\n",
    "expanded_queries.append(oroginal_query)\n",
    "\n",
    "expended_result_docs = []\n",
    "for query in expanded_queries:\n",
    "    print(\"Search for: \", query)\n",
    "    result_docs = retriever.invoke(query)\n",
    "    expended_result_docs.append(result_docs)\n",
    "\n",
    "# remove duplicates \n",
    "unique_docs = (list(set(expanded_queries)))\n",
    "print(\"expended_result_docs\", len(expended_result_docs))\n",
    "print(\"Unique docs:\", len(unique_docs))\n",
    "\n",
    "gc_result = chain.invoke({\"history\": history, \"context\": expanded_queries, \"input\": query})\n",
    "print(gc_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the Code: Smart Retrieval Augmented Generation (RAG)\n",
    "\n",
    "![Overview](./figures/a_in.png)\n",
    "\n",
    "### High-Level Overview\n",
    "\n",
    "The code demonstrates a smart Retrieval Augmented Generation (RAG) system that combines local retrieval with external search capabilities. The main goal is to provide relevant context for answering user questions by first searching a local vector database and then falling back to an external search service if the local context is insufficient.\n",
    "\n",
    "\n",
    "The code defines two main functions:\n",
    "\n",
    "\n",
    "  1. is_in: Determines whether the answer to a given question can be found within the provided context.\n",
    "smart_rag: Retrieves relevant context for a given question, either from the local vector database or an external search service, and generates an answer using the retrieved context.\n",
    "\n",
    "  1. The code uses the LangChain library for generating prompts and invoking language models, as well as the Tavily API for external search capabilities.\n",
    "\n",
    "\n",
    "### Detailed Explanation \n",
    "\n",
    "1. The code starts by defining the is_in function, which takes a question and context as input and determines whether the answer to the question can be found within the context.\n",
    "    * It defines a prompt template called is_in_conetxt that asks the language model to check if the answer is in the context and return \"yes\" or \"no\".\n",
    "    * The prompt template is used to create a ChatPromptTemplate object.\n",
    "    * A chain of operations is constructed using the | operator:\n",
    "      * The ChatPromptTemplate is passed to the ChatUpstage model.\n",
    "      * The model's output is parsed using the StrOutputParser.\n",
    "    * The chain is invoked with the question and context, and the response is stored in the response variable.\n",
    "    * The function returns True if the response starts with \"yes\" (case-insensitive), indicating that the answer is in the context.\n",
    "\n",
    "1. The code then demonstrates the usage of the is_in function with two example questions and their corresponding contexts retrieved from a retriever.\n",
    "\n",
    "1. Next, the code defines the smart_rag function, which takes a question as input and generates an answer using the retrieved context.\n",
    "    * It first retrieves the context for the question using the retriever.invoke method.\n",
    "    * If the is_in function determines that the answer is not in the retrieved context, it falls back to searching for additional context using the Tavily API.\n",
    "    * The retrieved context (either from the local retriever or Tavily) is stored in the context variable.\n",
    "    * A chain of operations is constructed using the | operator:\n",
    "      * The rag_with_history_prompt (not shown in the code snippet) is used as the prompt template.\n",
    "      * The prompt is passed to the llm language model.\n",
    "      * The model's output is parsed using the StrOutputParser.\n",
    "    * The chain is invoked with the conversation history, retrieved context, and the question, and the generated answer is returned.\n",
    "\n",
    "1. Finally, the code demonstrates the usage of the smart_rag function with two example questions:\n",
    "    * \"What is DUS?\": The answer is expected to be found in the local context.\n",
    "    * \"What's the population of San Francisco?\": The answer is not expected to be found in the local context, so it falls back to searching with Tavily.\n",
    "\n",
    "This code showcases how LangChain can be used to build a smart RAG system that combines local retrieval with external search capabilities. By first searching a local vector database and falling back to an external search service if needed, the system aims to provide relevant context for generating accurate answers to user questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG or Search?\n",
    "def is_in(question, context):\n",
    "    is_in_conetxt = \"\"\"As a helpful assistant, \n",
    "please use your best judgment to determine if the answer to the question is within the given context. \n",
    "If the answer is present in the context, please respond with \"yes\". \n",
    "If not, please respond with \"no\". \n",
    "Only provide \"yes\" or \"no\" and avoid including any additional information. \n",
    "Please do your best. Here is the question and the context.:\n",
    "---\n",
    "CONTEXT: {context}\n",
    "---\n",
    "QUESTION: {question}\n",
    "---\n",
    "OUTPUT (yes or no):\"\"\"\n",
    "\n",
    "    is_in_prompt = ChatPromptTemplate.from_template(is_in_conetxt)\n",
    "    chain = is_in_prompt | ChatUpstage() | StrOutputParser()\n",
    "\n",
    "    response = chain.invoke({\"history\": [], \"context\": context, \"question\": question})\n",
    "    print(response)\n",
    "    return response.lower().startswith(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "question = \"Can you tell me about Yi Sun-sin, a Korean admiral?\"\n",
    "context = retriever.invoke(question)\n",
    "print(is_in(question, context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "question = \"What is bug classification?\"\n",
    "context = retriever.invoke(question)\n",
    "print(is_in(question, context))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smart RAG, Self-Improving RAG\n",
    "from tavily import TavilyClient\n",
    "\n",
    "def smart_rag(question):\n",
    "    context = retriever.invoke(question)\n",
    "    if not is_in(question, context):\n",
    "        print(\"Searching in tavily\")\n",
    "        tavily = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "        context  = tavily.search(query=question)\n",
    "\n",
    "    chain = rag_with_history_prompt | llm | StrOutputParser()\n",
    "    return chain.invoke({\"history\": history, \"context\": context, \"input\": question})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "Searching in tavily\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Bug classification is a process that involves categorizing software bugs based on their characteristics, such as their severity, the component of the software they affect, or the type of error they represent. This process helps developers and quality assurance teams to prioritize and manage bugs more effectively.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is bug classification?\"\n",
    "smart_rag(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "Searching in tavily\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yi Sun-sin was a Korean admiral and a national hero in Korea. He was born on April 28, 1545, in Haeju, Gyeonggi-do, Korea, and is considered one of the greatest admirals and military strategists in history.\\n\\nYi Sun-sin served during the Japanese invasions of Korea in the 16th century. He is best known for his naval victories against the Japanese, despite being outnumbered and outgunned. His most famous victory was at the Battle of Myeongnyang, where he defeated a Japanese fleet of over 130 ships with only 13 of his own.\\n\\nYi Sun-sin is also known for his invention of the \"turtle ship,\" a type of armored warship that was heavily fortified and difficult to board or sink. The turtle ship had a wooden deck covered with spikes and a high, turtle-like shield that protected the crew from enemy fire.\\n\\nYi Sun-sin\\'s military strategies and tactics were highly effective, and his leadership inspired his troops to fight bravely against the Japanese. He was known for his bravery, wisdom, and loyalty to his country.\\n\\nYi Sun-sin died on December 16, 1598, during the Battle of Nojinpo. Despite his death, his legacy lives on, and he is remembered as a symbol of Korean resistance against foreign aggression. His life and achievements have been celebrated in numerous books, films, and plays, and he is still revered as a national hero in Korea.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Can you tell me about Yi Sun-sin, a Korean admiral?\"\n",
    "smart_rag(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the Code: Groundedness Check with LangChain and Upstage\n",
    "\n",
    "### High-Level Overview\n",
    "\n",
    "The provided code demonstrates how to perform a groundedness check using the LangChain library and the Upstage model. The groundedness check is a process of verifying whether the generated response is grounded in the given context. This is an important step in ensuring the quality and relevance of the generated output.\n",
    "\n",
    "The code uses the `UpstageGroundednessCheck` class from the `langchain_upstage` module to perform the groundedness check. It takes the context (a string of unique documents) and the generated response as input, and returns a verdict indicating whether the response is grounded or not.\n",
    "\n",
    "### Detailed Explanation\n",
    "\n",
    "1. The code starts by importing the necessary module:\n",
    "   - `UpstageGroundednessCheck` from `langchain_upstage`: This class is used to perform the groundedness check.\n",
    "\n",
    "2. An instance of the `UpstageGroundednessCheck` class is created and assigned to the variable `groundedness_check`.\n",
    "\n",
    "3. The input for the groundedness check is prepared by creating a dictionary called `request_input`:\n",
    "   - The `\"context\"` key is assigned the value of `str(unique_docs)`, which represents the unique documents as a string.\n",
    "   - The `\"answer\"` key is assigned the value of `response`, which represents the generated response.\n",
    "\n",
    "4. The `invoke` method of the `groundedness_check` instance is called with the `request_input` as an argument. This method performs the groundedness check and returns the verdict.\n",
    "\n",
    "5. The verdict is stored in the `response` variable and printed to the console using `print(response)`.\n",
    "\n",
    "6. The code then checks if the `response` starts with the word \"grounded\" (case-insensitive):\n",
    "   - If the response starts with \"grounded\", it means the groundedness check has passed, and the message \"✅ Groundedness check passed\" is printed.\n",
    "   - If the response does not start with \"grounded\", it means the groundedness check has failed, and the message \"❌ Groundedness check failed\" is printed.\n",
    "\n",
    "\n",
    "The provided code demonstrates a simple yet effective way to perform a groundedness check using LangChain and Upstage. By verifying whether the generated response is grounded in the given context, it helps ensure the quality and relevance of the output.\n",
    "\n",
    "Groundedness checks are an important step in building reliable and trustworthy language models and conversational agents. They help prevent the generation of irrelevant, inconsistent, or factually incorrect responses.\n",
    "\n",
    "By using the `UpstageGroundednessCheck` class from LangChain, developers can easily integrate groundedness checks into their language model pipelines and improve the overall performance of their systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grounded\n",
      "✅ Groundedness check passed\n"
     ]
    }
   ],
   "source": [
    "# GC\n",
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "\n",
    "groundedness_check = UpstageGroundednessCheck()\n",
    "\n",
    "context = \"DUS is a new approach developed by Upstage to improve the search quality.\"\n",
    "answer = \"DUS is developed by Upstage.\"\n",
    "\n",
    "request_input = {\n",
    "    \"context\": context,\n",
    "    \"answer\": answer,\n",
    "}\n",
    "gc_result = groundedness_check.invoke(request_input)\n",
    "\n",
    "print(gc_result)\n",
    "if gc_result.lower().startswith(\"grounded\"):\n",
    "    print(\"✅ Groundedness check passed\")\n",
    "else:\n",
    "    print(\"❌ Groundedness check failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Groundedness check failed\n"
     ]
    }
   ],
   "source": [
    "context = \"DUS is a new approach developed by Upstage to improve the search quality.\"\n",
    "answer = \"DUS is developed by Google.\"\n",
    "\n",
    "request_input = {\n",
    "    \"context\": context,\n",
    "    \"answer\": answer,\n",
    "}\n",
    "gc_result = groundedness_check.invoke(request_input)\n",
    "\n",
    "if gc_result.lower().startswith(\"grounded\"):\n",
    "    print(\"✅ Groundedness check passed\")\n",
    "else:\n",
    "    print(\"❌ Groundedness check failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Tools in LangChain\n",
    "\n",
    "### High-Level Overview\n",
    "\n",
    "The provided code demonstrates how to create custom tools in LangChain, a framework for developing applications powered by language models. Tools are essential components in LangChain that allow language models to perform specific tasks or access external resources.\n",
    "\n",
    "The code defines three custom tools:\n",
    "\n",
    "1. `add`: A tool that adds two integers.\n",
    "2. `multiply`: A tool that multiplies two integers.\n",
    "3. `get_news`: A tool that retrieves news articles on a given topic using an external API.\n",
    "\n",
    "These tools are then bound to a language model using the `bind_tools` method, enabling the model to utilize these tools when generating responses.\n",
    "\n",
    "### Detailed Explanation\n",
    "\n",
    "Let's break down the code and explain each part in detail:\n",
    "\n",
    "1. Importing necessary modules:\n",
    "   - `tool` from `langchain_core.tools`: This module provides the `@tool` decorator for defining custom tools.\n",
    "   - `requests`: A library for making HTTP requests to external APIs.\n",
    "\n",
    "2. Defining the `add` tool:\n",
    "   - The `@tool` decorator is used to define the `add` function as a custom tool.\n",
    "   - The function takes two integer parameters, `a` and `b`, and returns their sum.\n",
    "   - The docstring provides a brief description of the tool's functionality.\n",
    "\n",
    "3. Defining the `multiply` tool:\n",
    "   - Similar to the `add` tool, the `multiply` function is defined as a custom tool using the `@tool` decorator.\n",
    "   - It takes two integer parameters, `a` and `b`, and returns their product.\n",
    "   - The docstring describes the tool's purpose.\n",
    "\n",
    "4. Defining the `get_news` tool:\n",
    "   - The `get_news` function is defined as a custom tool using the `@tool` decorator.\n",
    "   - It takes a `topic` parameter of type `str` and returns news articles related to that topic.\n",
    "   - The function constructs a URL for the news API using the provided topic and an API key stored in an environment variable.\n",
    "   - It sends a GET request to the API using the `requests` library and returns the JSON response.\n",
    "\n",
    "5. Creating a list of tools:\n",
    "   - The `tools` list is created, containing the `add`, `multiply`, and `get_news` tools.\n",
    "   - This list will be used to bind the tools to the language model.\n",
    "\n",
    "6. Binding the tools to the language model:\n",
    "   - The `bind_tools` method of the `llm` object is called, passing the `tools` list as an argument.\n",
    "   - This step binds the custom tools to the language model, allowing it to utilize these tools when generating responses.\n",
    "   - The resulting object is assigned to the variable `llm_with_tools`.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "The code demonstrates how to create custom tools in LangChain, which can be used to extend the capabilities of language models. By defining tools for specific tasks, such as mathematical operations or retrieving news articles, developers can enhance the functionality of their LangChain applications.\n",
    "\n",
    "The `@tool` decorator simplifies the process of defining custom tools, while the `bind_tools` method allows seamless integration of these tools with the language model.\n",
    "\n",
    "By leveraging custom tools, LangChain enables developers to build powerful and versatile applications that can perform a wide range of tasks beyond simple text generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def get_news(topic: str) -> str:\n",
    "    \"\"\"Get news on a given topic.\"\"\"\n",
    "    # https://newsapi.org/v2/everything?q=tesla&from=2024-04-01&sortBy=publishedAt&apiKey=API_KEY\n",
    "    # change this to request news from a real API\n",
    "    news_url = f\"https://newsapi.org/v2/everything?q={topic}&apiKey={os.environ['NEWS_API_KEY']}\"\n",
    "    respnse = requests.get(news_url)\n",
    "    return respnse.json()\n",
    "\n",
    "tools = [add, multiply, get_news]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tool(tool_call):\n",
    "    tool_name = tool_call[\"name\"].lower()\n",
    "    if tool_name not in globals():\n",
    "        print(\"Tool not found\", tool_name)\n",
    "        return None\n",
    "    selected_tool = globals()[tool_name]\n",
    "    return selected_tool.invoke(tool_call[\"args\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'add', 'args': {'a': 11, 'b': 49}, 'id': '3e260170-5fe8-4db6-a90c-7b8c8c7e428c'}, {'name': 'multiply', 'args': {'a': 3, 'b': 12}, 'id': '4398e790-7007-4b54-af88-da3716cb60fa'}]\n"
     ]
    }
   ],
   "source": [
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "tool_calls = llm_with_tools.invoke(query).tool_calls\n",
    "print(tool_calls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "for tool_call in tool_calls:\n",
    "    print(call_tool(tool_call))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'get_news', 'args': {'topic': 'NewJeans'}, 'id': 'a2172b6b-ee6d-43ef-840b-04d35f207a03'}]\n",
      "{'status': 'ok', 'totalResults': 284, 'articles': [{'source': {'id': 'the-verge', 'name': 'The Verge'}, 'author': 'Amrita Khalid', 'title': 'You don’t know your K-pop persona, do you?', 'description':\n"
     ]
    }
   ],
   "source": [
    "query = \"What's news on NewJeans?\"\n",
    "\n",
    "tool_calls = llm_with_tools.invoke(query).tool_calls\n",
    "print(tool_calls)\n",
    "\n",
    "for tool_call in tool_calls:\n",
    "    print(str(call_tool(tool_call))[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚀 Exciting Excercise: Building Your Own AI-Powered Chatbot! 🤖\n",
    "\n",
    "### Introduction\n",
    "\n",
    "Congratulations on completing the course on building chatbots using Language Models (LLMs), Layout Analysis (LA), custom tools, and Groundedness Checks (GC)! It's time to put your skills to the test by creating your own AI-powered chatbot. 🎉\n",
    "\n",
    "### Objective\n",
    "\n",
    "Your task is to develop a chatbot that can perform various tasks based on user queries, such as:\n",
    "\n",
    "- 🎨 Drawing images based on user descriptions\n",
    "- 📰 Searching for the latest news on various topics\n",
    "- 📅 Checking and managing schedules\n",
    "- 📄 Extracting structured information from PDFs and images using Layout Analysis\n",
    "- 🌟 And more!\n",
    "\n",
    "### Requirements\n",
    "\n",
    "To create your chatbot, you'll need to leverage the following components:\n",
    "\n",
    "1. 🧠 Language Model (LLM): Use a powerful LLM to understand user queries and generate responses.\n",
    "\n",
    "2. 📊 Layout Analysis (LA): Utilize Layout Analysis techniques to extract structured information from PDFs and images.\n",
    "\n",
    "3. 🛠️ Custom Tools: Develop custom tools for specific actions like image generation, news search, and schedule management.\n",
    "\n",
    "4. ✅ Groundedness Check (GC): Implement a groundedness check to ensure relevant and accurate responses.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "This homework assignment is your opportunity to showcase your skills in building an AI-powered chatbot that can understand and process visual content using Layout Analysis. Have fun and be creative! 🚀\n",
    "\n",
    "Happy coding, and may your chatbot impress everyone! 😄"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
